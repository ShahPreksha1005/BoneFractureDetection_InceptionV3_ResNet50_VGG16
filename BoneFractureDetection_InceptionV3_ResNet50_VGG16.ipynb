{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'fracture-multi-region-x-ray-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4854718%2F8201044%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240830%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240830T043158Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D58f12c63bebc33f5d002f1eec3fd7d213250b69483ad3704481a486506f75b9dfe0e20516700c702fbcb5178f2b11456d9974c71aa746a49ed218e852fd29f8db7547deb4ec38428aec0e7168dcdfd7be26c7f2909f5f4fc1885248216c11db1d2e770482419085c31ed6b41b5ef801ebc15d7759188b0e9124ca66591f0fd8a9618681fc607832d7958c8f738c89843f06e1909fc57c4005e211583816f4d013705d36306bd6c62adeeaed0f17071ca831a14b9ea8f5880db5a34364aa6763f308649f819f759f5d37eff3f0325aa68e9b450b765a6940adaf694afafab657ca9606871d93477e024f064ab81c408a922a2dd868cbe6dea767d111572c2fe93'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUXE4evVjmgs",
        "outputId": "a2055682-d002-4dcc-9dcd-10f232aa2ae2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fracture-multi-region-x-ray-data, 504652653 bytes compressed\n",
            "[==================================================] 504652653 bytes downloaded\n",
            "Downloaded and uncompressed: fracture-multi-region-x-ray-data\n",
            "Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **Bone Fracture Detection using Neural Networks**\n",
        "\n",
        "## **Introduction**\n",
        "\n",
        "Bone fractures are a common medical issue requiring prompt detection. Machine learning, particularly neural networks, offers potential improvements in fracture detection from X-ray images. This assignment explores various neural network models to enhance diagnostic accuracy.\n",
        "\n",
        "## **Problem Statement**\n",
        "\n",
        "The task is to develop and evaluate several neural network models for detecting bone fractures from X-ray images. The objective is to determine which model provides the best performance for accurate fracture detection.\n",
        "\n",
        "## **Objectives**\n",
        "\n",
        "1. **Implement Neural Network Architectures and Deep Learning Models**\n",
        "2. **Evaluate and Compare Various Models**\n",
        "3. **Visualize and Analyze Results**\n",
        "4. **Document Findings**\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Import Libraries**\n"
      ],
      "metadata": {
        "id": "1OnB9hV_hR4t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "HrEPXIR7JyLa"
      },
      "outputs": [],
      "source": [
        "# Importing Dependencies\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Conv2D, Dropout, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Load and Pre-process Images\"\"**"
      ],
      "metadata": {
        "id": "qbYYZkBQhfEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to do necessary preprocessing\n",
        "def load_images(directory):\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        try:\n",
        "            img = Image.open(os.path.join(directory, filename))\n",
        "            img = img.resize((128, 128))\n",
        "            img = img.convert('RGB')\n",
        "            img = np.array(img) / 255.0\n",
        "            images.append(img)\n",
        "        except OSError as e:\n",
        "            print(f\"Error loading {os.path.join(directory, filename)}: {e}\")\n",
        "            continue\n",
        "    return images"
      ],
      "metadata": {
        "id": "7ob0D_7MaDyF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to do necessary preprocessing\n",
        "def load_and_preprocess_images(directory):\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        try:\n",
        "            img = Image.open(os.path.join(directory, filename))\n",
        "            img = img.resize((128, 128))\n",
        "            img = img.convert('RGB')\n",
        "            img = np.array(img) / 255.0\n",
        "            images.append(img)\n",
        "        except OSError as e:\n",
        "            print(f\"Error loading {os.path.join(directory, filename)}: {e}\")\n",
        "            continue\n",
        "    return np.array(images)"
      ],
      "metadata": {
        "id": "ZlPNllrul26e"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data\n",
        "fractured_test = load_and_preprocess_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/fractured')\n",
        "fractured_train = load_and_preprocess_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/fractured')\n",
        "fractured_val = load_and_preprocess_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/fractured')\n",
        "not_fractured_test = load_and_preprocess_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured')\n",
        "not_fractured_train = load_and_preprocess_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured')\n",
        "not_fractured_val = load_and_preprocess_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/not fractured')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sycIILRYaLOC",
        "outputId": "271dba93-db52-4d5c-9f1c-b84c9c894095"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured/IMG0004347.jpg: image file is truncated (40 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured/IMG0004148.jpg: image file is truncated (14 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured/IMG0004149.jpg: image file is truncated (33 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured/IMG0004308.jpg: image file is truncated (40 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured/IMG0004134.jpg: image file is truncated (1 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured/IMG0004143.jpg: image file is truncated (10 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured/IMG0004347.jpg: image file is truncated (40 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured/IMG0004148.jpg: image file is truncated (14 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured/IMG0004149.jpg: image file is truncated (33 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured/IMG0004308.jpg: image file is truncated (40 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured/IMG0004134.jpg: image file is truncated (1 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured/IMG0004143.jpg: image file is truncated (10 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/not fractured/IMG0004347.jpg: image file is truncated (40 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/not fractured/IMG0004148.jpg: image file is truncated (14 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/not fractured/IMG0004149.jpg: image file is truncated (33 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/not fractured/IMG0004308.jpg: image file is truncated (40 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/not fractured/IMG0004134.jpg: image file is truncated (1 bytes not processed)\n",
            "Error loading /kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/not fractured/IMG0004143.jpg: image file is truncated (10 bytes not processed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating labels\n",
        "fractured_train_labels = np.ones(len(fractured_train))\n",
        "fractured_val_labels = np.ones(len(fractured_val))\n",
        "fractured_test_labels = np.ones(len(fractured_test))\n",
        "\n",
        "not_fractured_train_labels = np.zeros(len(not_fractured_train))\n",
        "not_fractured_val_labels = np.zeros(len(not_fractured_val))\n",
        "not_fractured_test_labels = np.zeros(len(not_fractured_test))"
      ],
      "metadata": {
        "id": "8BEGL5gvl-Bv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining fractured and non-fractured data\n",
        "X_train = np.concatenate([fractured_train, not_fractured_train], axis=0)\n",
        "y_train = np.concatenate([fractured_train_labels, not_fractured_train_labels], axis=0)\n",
        "\n",
        "X_val = np.concatenate([fractured_val, not_fractured_val], axis=0)\n",
        "y_val = np.concatenate([fractured_val_labels, not_fractured_val_labels], axis=0)\n",
        "\n",
        "X_test = np.concatenate([fractured_test, not_fractured_test], axis=0)\n",
        "y_test = np.concatenate([fractured_test_labels, not_fractured_test_labels], axis=0)\n"
      ],
      "metadata": {
        "id": "Z2016Fcol-iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the data\n",
        "fig, axes = plt.subplots(1, 6, figsize=(20, 10))\n",
        "axes[0].imshow(fractured_test[0])\n",
        "axes[1].imshow(fractured_train[0])\n",
        "axes[2].imshow(fractured_val[0])\n",
        "axes[3].imshow(not_fractured_test[0])\n",
        "axes[4].imshow(not_fractured_train[0])\n",
        "axes[5].imshow(not_fractured_val[0])\n",
        "axes[0].set_title('Fractured')\n",
        "axes[1].set_title('Fractured')\n",
        "axes[2].set_title('Fractured')\n",
        "axes[3].set_title('Not Fractured')\n",
        "axes[4].set_title('Not Fractured')\n",
        "axes[5].set_title('Not Fractured')\n",
        "for ax in axes:\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vzfIN_DWl-lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Data Augmentation**"
      ],
      "metadata": {
        "id": "pU3wKmMpmJ6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "p70H69cWl-oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Defining Neural Network Architectures**\n",
        "### **4.1 Custom CNN Model**"
      ],
      "metadata": {
        "id": "0SPXkx5XmPr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom CNN Model building\n",
        "\n",
        "def create_custom_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "SoyQQlm3l-yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2 VGG16 Model**"
      ],
      "metadata": {
        "id": "TFrBhXZPnFe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 Model Building\n",
        "\n",
        "def create_vgg16_model(input_shape):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "cBMPKKx6l-1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3 ResNet50 Model**"
      ],
      "metadata": {
        "id": "r8g3LHOPnSD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50 Model building\n",
        "\n",
        "def create_resnet50_model(input_shape):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "-yPQepkyl-4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.4 InceptionV3 Model**"
      ],
      "metadata": {
        "id": "ZpFGQisbnlRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# InceptionV3 Model\n",
        "\n",
        "def create_inceptionv3_model(input_shape):\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "jXVaB8_1niDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Model Training**"
      ],
      "metadata": {
        "id": "b07e9vhmoEls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "def train_model(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=10):\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        epochs=epochs)\n",
        "    return history"
      ],
      "metadata": {
        "id": "4fKOz3fsniGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom CNN Training\n",
        "custom_cnn_model = create_custom_cnn((128, 128, 3))\n",
        "history_custom_cnn = train_model(custom_cnn_model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "# VGG16 Training\n",
        "vgg16_model = create_vgg16_model((128, 128, 3))\n",
        "history_vgg16 = train_model(vgg16_model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "# ResNet50 Training\n",
        "resnet50_model = create_resnet50_model((128, 128, 3))\n",
        "history_resnet50 = train_model(resnet50_model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "# InceptionV3 Training\n",
        "inceptionv3_model = create_inceptionv3_model((128, 128, 3))\n",
        "history_inceptionv3 = train_model(inceptionv3_model, X_train, y_train, X_val, y_val)\n"
      ],
      "metadata": {
        "id": "Eg1c0k00niI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**6. Model Evaluations**"
      ],
      "metadata": {
        "id": "6BqbHXc7pdCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **5. Evaluating the Models**\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cm, cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "y9wvdRDxniRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom CNN Evaluation\n",
        "print(\"Custom CNN Evaluation:\")\n",
        "evaluate_model(custom_cnn_model, X_test, y_test)\n",
        "\n",
        "# VGG16 Evaluation\n",
        "print(\"VGG16 Evaluation:\")\n",
        "evaluate_model(vgg16_model, X_test, y_test)\n",
        "\n",
        "# ResNet50 Evaluation\n",
        "print(\"ResNet50 Evaluation:\")\n",
        "evaluate_model(resnet50_model, X_test, y_test)\n",
        "\n",
        "# InceptionV3 Evaluation\n",
        "print(\"InceptionV3 Evaluation:\")\n",
        "evaluate_model(inceptionv3_model, X_test, y_test)"
      ],
      "metadata": {
        "id": "xydciugRniUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Visualizing Training Results**"
      ],
      "metadata": {
        "id": "M01exn-pp6Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Training Results\n",
        "\n",
        "def plot_training_history(history, model_name):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plotting training & validation accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotting training & validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{model_name} Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ktzvzBTyniYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom CNN Training History\n",
        "plot_training_history(history_custom_cnn, \"Custom CNN\")\n",
        "\n",
        "# VGG16 Training History\n",
        "plot_training_history(history_vgg16, \"VGG16\")\n",
        "\n",
        "# ResNet50 Training History\n",
        "plot_training_history(history_resnet50, \"ResNet50\")\n",
        "\n",
        "# InceptionV3 Training History**\n",
        "plot_training_history(history_inceptionv3, \"InceptionV3\")"
      ],
      "metadata": {
        "id": "tw5wFWN-p-o9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}